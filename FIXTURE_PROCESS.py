#è®¾ç½®é¡µé¢
import streamlit as st
st.set_page_config(layout="wide") #å®½å±æ¨¡å¼
#st.text('updated') #st.textå°±æ˜¯ç›´æ¥åœ¨é¡µé¢ä¸Šæ˜¾ç¤ºæ–‡æœ¬
st.title('Baltic Fixture Dashboard')

# ä¾èµ–é¡¹
import warnings; warnings.simplefilter('ignore') #æŠŠ Python çš„æ‰€æœ‰è­¦å‘Šï¼ˆå¦‚é“¾å¼èµ‹å€¼ã€è¿‡æœŸ APIï¼‰é™é»˜æ‰ï¼Œè®©æ§åˆ¶å°å¹²å‡€ï¼Œè°ƒè¯•é˜¶æ®µå¯æ³¨é‡Šæ‰ä»¥ä¾¿å‘ç°æ½œåœ¨é—®é¢˜ã€‚
import pandas as pd
import time
import re
import numpy as np
from datetime import date
from calendar import monthrange
from pandas.tseries.offsets import BDay # Bdayæ˜¯å·¥ä½œæ—¥
import requests
import os
from pathlib import Path
import ftplib #æ³¢ç½—çš„æµ·å®˜ç½‘/éƒ¨åˆ†ç»çºªè¡Œä»æä¾› FTP ä¸‹è½½ï¼ˆtxt/csv æ ¼å¼ï¼‰ï¼Œç”¨æ¥è‡ªåŠ¨æŠ“å†å²æŒ‡æ•°ã€‚

# æ·»åŠ é…ç½®ç®¡ç†æ¨¡å—
try:
    from config_manager import ConfigManager, init_session_config
    CONFIG_MANAGER_AVAILABLE = True
except ImportError:
    CONFIG_MANAGER_AVAILABLE = False
    st.warning("é…ç½®ç®¡ç†æ¨¡å—æœªæ‰¾åˆ°ï¼Œå°†åˆ›å»ºé»˜è®¤é…ç½®ç®¡ç†å™¨")

pd.set_option('display.max_rows',None)
pd.set_option('display.max_columns',None)
#è®© DataFrame ä¸ç®¡å¤šå°‘è¡Œéƒ½ å…¨éƒ¨æ‰“å°å‡ºæ¥ï¼Œä¸å†å‡ºç°ä¸­é—´çœç•¥å·ï¼Œè¿™ä¸¤è¡Œåªæ˜¯æ–¹ä¾¿ å¼€å‘è°ƒè¯•é˜¶æ®µ åœ¨æ§åˆ¶å°é‡Œä¸€çœ¼çœ‹å…¨è¡¨ï¼›ä¸Šçº¿åå¯ä»¥ä¿ç•™ï¼Œä¹Ÿå¯ä»¥åˆ æ‰ï¼Œå¯¹æœ€ç»ˆç”¨æˆ·ç•Œé¢æ²¡æœ‰ä»»ä½•å½±å“ã€‚

# ==================== åˆå§‹åŒ–é…ç½® ====================
def initialize_config():
    """åˆå§‹åŒ–é…ç½®ç®¡ç†ç³»ç»Ÿ"""
    if CONFIG_MANAGER_AVAILABLE:
        try:
            init_session_config()
            st.success("âœ… é…ç½®ç³»ç»Ÿå·²åˆå§‹åŒ–")
            
            # æ˜¾ç¤ºé…ç½®çŠ¶æ€
            if 'app_config' in st.session_state:
                config = st.session_state.app_config
                if 'custom_sets' in config:
                    set_count = len(config['custom_sets'])
                    st.info(f"ğŸ“š åŠ è½½äº† {set_count} ä¸ªè‡ªå®šä¹‰ç­›é€‰é›†åˆ")
                else:
                    st.info("ğŸ“š æ— è‡ªå®šä¹‰ç­›é€‰é›†åˆï¼Œè¯·åœ¨æ•°æ®ç®¡ç†é¡µé¢åˆ›å»º")
        except Exception as e:
            st.warning(f"é…ç½®åˆå§‹åŒ–å¤±è´¥: {e}")
            # åˆ›å»ºåŸºæœ¬çš„é…ç½®ç®¡ç†å™¨
            create_fallback_config()
    else:
        # åˆ›å»ºåŸºæœ¬çš„é…ç½®ç®¡ç†å™¨
        create_fallback_config()

def create_fallback_config():
    """åˆ›å»ºå›é€€é…ç½®"""
    default_config = {
        "custom_sets": {
            "Australia": {
                "keywords": [
                    "AUSTRALIA", "AUS", "WESTERN AUSTRALIA", "WA",
                    "QUEENSLAND", "QLD", "NEW SOUTH WALES", "NSW",
                    "VICTORIA", "VIC", "SOUTH AUSTRALIA", "SA",
                    "TASMANIA", "TAS", "NORTHERN TERRITORY", "NT",
                    "SYDNEY", "MELBOURNE", "BRISBANE", "PERTH",
                    "ADELAIDE", "DARWIN", "HOBART", "NEWCASTLE",
                    "FREMANTLE", "GEELONG", "PORT KEMBLA",
                    "TOWNSVILLE", "CAIRNS", "GLADSTONE", "MACKAY",
                    "BUNBURY", "ESPERANCE", "ALBANY", "PORT LINCOLN",
                    "PORT HEDLAND", "DAMPIER", "HAY POINT", "ABBOT POINT",
                    "PORT WALCOTT", "CAPE LAMBERT", "PORT ALMA",
                    "PORT BOTANY", "PORT OF BRISBANE", "PORT OF MELBOURNE",
                    "PORT OF ADELAIDE", "PORT OF FREMANTLE",
                    "WEIPA", "GOVE", "KARRATHA", "GERALDTON",
                    "BROOME", "PORTLAND", "BURNIE", "DEVONPORT",
                    "PORT PIRIE", "WHYALLA", "PORT GILES"
                ],
                "description": "æ¾³å¤§åˆ©äºšæ¸¯å£é›†åˆ",
                "created_at": date.today().isoformat(),
                "is_template": True
            },
            "ECSA": {
                "keywords": ["ECSA", "EAST COAST SOUTH AMERICA", "BRAZIL", "ARGENTINA", "URUGUAY"],
                "description": "ä¸œæµ·å²¸å—ç¾æ´²æ¸¯å£",
                "created_at": date.today().isoformat(),
                "is_template": True
            },
            "USG": {
                "keywords": ["US GULF", "USGC", "GULF COAST", "HOUSTON", "NEW ORLEANS"],
                "description": "ç¾å›½å¢¨è¥¿å“¥æ¹¾æ¸¯å£",
                "created_at": date.today().isoformat(),
                "is_template": True
            }
        },
        "version": "2.0",
        "last_modified": date.today().isoformat()
    }
    
    # ä¿å­˜åˆ° session state
    st.session_state.app_config = default_config
    st.info("ğŸ“š ä½¿ç”¨é»˜è®¤é…ç½®ï¼ŒåŒ…å« 3 ä¸ªé¢„å®šä¹‰ç­›é€‰é›†åˆ")

# åˆå§‹åŒ–é…ç½®
initialize_config()

#é¡µé¢æ˜¾ç¤º
st.write('Loading Data...')
st.text('----Getting Fixture Data...')

#Getting Spot Fixture Data
#ã€Œå…œåº•å¤‡ä»½ã€å‡½æ•°ï¼šå½“ API æ— æ³•è®¿é—®ã€ç½‘ç»œæ•…éšœã€æˆ–è€…æœ¬åœ°æƒ³å¿«é€Ÿè°ƒè¯•æ—¶ï¼Œä¸æ‹‰å®æ—¶æ¥å£ï¼Œç›´æ¥è¯»æœ¬åœ°ä¸€ä»½é™æ€å…¨å†å²æ–‡ä»¶ Baltic Exchange - Historic Data.csvï¼Œè¿”å›åŒæ ·ç»“æ„çš„ DataFrameï¼Œè®©åç»­ä»£ç æ— æ„ŸçŸ¥åˆ‡æ¢ã€‚
@st.cache_data()
def load_spot_data_backup():
    spot=pd.read_csv('Baltic Exchange - Historic Data.csv')
    spot.set_index('date',inplace=True)
    spot.index=pd.to_datetime(spot.index,dayfirst=True) #å¼ºåˆ¶æŠŠç´¢å¼•è½¬æˆæ—¶é—´ç´¢å¼•ï¼›dayfirst=True å‘Šè¯‰è§£æå™¨ã€Œæ—¥/æœˆ/å¹´ã€æ ¼å¼ï¼ˆæ¬§æ´²é£æ ¼ï¼‰ã€‚
    #spot=spot[spot.index>=pd.to_datetime(date(2015,1,1))]

    return spot
# ----------  é€šç”¨å¼•æ“å­—ç¬¦åŒ¹é…å‡½æ•° ----------
def enrich(df: pd.DataFrame, maps: dict) -> pd.DataFrame:
    """
    å¯¹ DataFrame ä¸­æŒ‡å®šåˆ—è¿›è¡Œ"ç©ºå€¼è¡¥å…¨"ï¼š
    1. åŸåˆ—å·²æœ‰éç©ºå€¼ â†’ åŸæ ·ä¿ç•™
    2. åŸåˆ—ä¸º NaN / ç©ºå­—ç¬¦ä¸² / ä»…ç©ºæ ¼ â†’ ç”¨æ­£åˆ™ä» fixtureString æå–å¹¶å¡«å……
    3. è‹¥å­—å…¸ä¸­çš„åˆ—ååœ¨è¡¨ä¸­ä¸å­˜åœ¨ â†’ å…ˆåˆ›å»ºå…¨ NaN åˆ—ï¼Œå†æŒ‰è§„åˆ™å¡«å……
    è¿”å›ï¼šå¡«å……åçš„æ–° DataFrameï¼ˆä¸ä¿®æ”¹åŸè¡¨ï¼‰
    """
    # æ·±æ‹·è´ï¼Œé¿å…ä¿®æ”¹åŸè¡¨
    df = df.copy()

    # ç»Ÿä¸€æŠŠ fixtureString è½¬æˆå­—ç¬¦ä¸²ï¼Œé˜²æ­¢ NaN å¯¼è‡´æ­£åˆ™æŠ¥é”™
    txt = df['fixtureString'].astype(str)

    # éå†æ­£åˆ™åœ°å›¾ {å­—æ®µå: ç¼–è¯‘å¥½çš„æ­£åˆ™}
    for col, pat in maps.items():
        # å¦‚æœè¯¥åˆ—åœ¨è¡¨ä¸­ä¸å­˜åœ¨ï¼ˆä¾‹å¦‚æ–°å¢ Via/Redel/Hireï¼‰ï¼Œå…ˆåˆ›å»ºå…¨ NaN åˆ—
        if col not in df.columns:
            df[col] = None

        # æ„é€ æ©ç ï¼šTrue è¡¨ç¤ºéœ€è¦è¡¥å…¨ï¼ˆNaN æˆ–ç©ºå­—ç¬¦ä¸²æˆ–ä»…ç©ºæ ¼ï¼‰
        mask = pd.isna(df[col]) | (df[col].astype(str).str.strip() == '')

        # å†…éƒ¨å·¥å…·å‡½æ•°ï¼šå¯¹å•è¡Œæ–‡æœ¬è·‘æ­£åˆ™ï¼Œå‘½ä¸­è¿”å›æ•è·ç»„1å¹¶å»ç©ºæ ¼ï¼Œå¦åˆ™è¿”å› None
        def extract_text(x):
            if pd.isna(x):               # æœ¬èº«æ˜¯ NaN ç›´æ¥è¿”å› None
                return None
            m = pat.search(x)            # è·‘æ­£åˆ™
            return m.group(1).strip() if m else None  # å‘½ä¸­â†’å»ç©ºæ ¼ï¼Œæœªå‘½ä¸­â†’None

        # åªå¯¹"ç©º"è¡Œè·‘æ­£åˆ™ï¼Œç»“æœå†™å›åŒä¸€åˆ—
        df.loc[mask, col] = txt[mask].apply(extract_text)

    # è¿”å›å¡«å……/æ–°å¢åˆ—åçš„æ–°è¡¨
    return df
# ---------- è¾…åŠ©å‡½æ•°ï¼šæ·»åŠ  VESSEL TYPE åˆ— ----------
def add_vessel_type(df):
    """æ ¹æ® dwt åˆ—æ·»åŠ  VESSEL TYPE åˆ—"""
    if df is None or df.empty:
        return df
    
    df = df.copy()
    
    # ç¡®ä¿ dwt åˆ—å­˜åœ¨
    if 'dwt' not in df.columns:
        df['dwt'] = None
    
    # å¤„ç† dwt åˆ—ï¼šè½¬æ¢ä¸ºæ•°å€¼ï¼Œå»é™¤é€—å·ç­‰
    def parse_dwt(x):
        if pd.isna(x):
            return None
        try:
            # å»é™¤é€—å·å’Œç©ºæ ¼
            x_str = str(x).replace(',', '').strip()
            # æå–æ•°å­—éƒ¨åˆ†
            match = re.search(r'(\d+)', x_str)
            if match:
                return int(match.group(1))
            return None
        except:
            return None
    
    # åˆ›å»ºæ•°å€¼å‹çš„ dwt åˆ—ç”¨äºåˆ¤æ–­
    df['dwt_numeric'] = df['dwt'].apply(parse_dwt)
    
    # æ ¹æ® dwt_numeric åˆ¤æ–­èˆ¹èˆ¶ç±»å‹
    def determine_vessel_type(dwt_val):
        if pd.isna(dwt_val):
            return None
        
        try:
            dwt_num = float(dwt_val)
            if dwt_num > 100000:
                return 'CAPE/VLOC'
            elif dwt_num > 80000 and dwt_num < 100000:
                return 'KMX'
            elif dwt_num >= 65000 and dwt_num <= 80000:
                return 'PMX'
            elif dwt_num < 65000:
                return 'SMX/UMX/HANDY'
            else:
                return None
        except:
            return None
    
    # æ·»åŠ  VESSEL TYPE åˆ—
    df['VESSEL TYPE'] = df['dwt_numeric'].apply(determine_vessel_type)
    
    # åˆ é™¤ä¸´æ—¶çš„ dwt_numeric åˆ—
    if 'dwt_numeric' in df.columns:
        df = df.drop(columns=['dwt_numeric'])
    
    return df

#TCç±»å‹æ­£åˆ™è¡¥å…¨ä½¿ç”¨
TC_RE_MAPS = {
    # chrträ¸åŒ¹é…äº†ï¼Œå› ä¸ºå¥½åƒéƒ½å†™äº†ï¼Œè€Œä¸”æ¯”è¾ƒéš¾åŒ¹é…ï¼Œå› ä¸ºä¸å¥½å®šä½--
    'shipName': re.compile(r"'([^']+)'", re.I), #æ‰¾åˆ°ç¬¬ä¸€å¯¹å•å¼•å·ï¼ŒæŠŠä¸­é—´ä¸æ˜¯å•å¼•å·çš„é‚£ä¸²å­—ç¬¦æŠ“å‡ºæ¥ï¼Œå°±æ˜¯èˆ¹åã€‚re.Iå¿½ç•¥å¤§å°å†™
    'buildYear': re.compile(r"'[^']+'\s+(\d{4})", re.I), #ä½†å› ä¸­èˆ¹ååé¢çš„å››ä½æ•°å­—æŠ“å‡ºæ¥
    'dwt': re.compile(r"(\d+)\s+dwt", re.I), #dwtå‰ä¸€ä¸²æ•°å­—æŠ“å‡ºæ¥ï¼Œå³dwtçš„éƒ¨åˆ†
    'deliveryPort': re.compile(r"dely\s+(.*?)(?=\s+(?:\d+(?:/\d+)?\s+\w+|prompt)\s+trip\b)", re.I),#ä» dely åé¢å¼€å§‹ï¼Œä»»æ„å­—ç¬¦ï¼ˆéè´ªå©ªï¼‰ä¸€ç›´å¾€å‰æ‰«ï¼Œç›´åˆ°ç¬¬ä¸€æ¬¡å‡ºç°"æ•°å­—+ä»»æ„å•è¯+trip" æˆ– "prompt+trip" å°±åœï¼ŒæŠŠä¸­é—´é‚£æ®µä»»æ„å­—ç¬¦ä½œä¸ºäº¤èˆ¹æ¸¯å£åè¿”å›ã€‚
    'freeText': re.compile(r'dely[\s\S]*?\b(\d+(?:/\d+)?\s+[A-Za-z]+|prompt)(?=\s+trip\b)', re.I),#æŠ“del+å­—ç¬¦åé¢çš„ æ•°å­—+ä»»æ„é•¿åº¦æœˆä»½å•è¯ æˆ– prompt
    'comment': re.compile(r"<([^>]+)>", re.I),#å–ç¬¬ä¸€å¯¹å°–æ‹¬å· <...> ä¹‹é—´çš„ä»»æ„å­—ç¬¦
    'via': re.compile(r'\bvia\s+(.*?)(?=\s+redel\b)', re.I),#viaå’Œredlä¹‹é—´çš„å­—ç¬¦
    'redel': re.compile(r'\bredel\s+(.*?)(?=\s*\$)', re.I),#redelå’Œ$ä¹‹é—´çš„å†…å®¹
    'hire': re.compile(r'(\$.*?)(?:\s*-|$)', re.I),#ä»ç¬¬ä¸€ä¸ªç¾å…ƒç¬¦å·å¼€å§‹ï¼Œä¸€ç›´ååˆ°ç¬¬ä¸€ä¸ª - æˆ–è¡Œå°¾ä¹‹å‰ç»“æŸï¼Œå†…å®¹ä¸é™
}
@st.cache_data()
def load_tc_data(days_back: int = 1):
    headers = {'x-apikey': 'FMNNXJKJMSV6PE4YA36EOAAJXX1WAH84KSWNU8PEUFGRHUPJZA3QTG1FLE09SXJF'}
    dateto=pd.to_datetime('today')-BDay(1) #è·å–ä»£ç è¿è¡Œå½“æ—¥æ—¥æœŸ
    datefrom=dateto-BDay(days_back) #å‘å‰æ¨15ä¸ªå·¥ä½œæ—¥ï¼Œä¸è€ƒè™‘èŠ‚å‡æ—¥ï¼Œå¾—åˆ°15æ—¥çš„æ•°æ®ã€‚æ„æ€æ˜¯å…è®¸æ–­æ›´15å¤©ã€‚å› ä¸ºå¯èƒ½æœ‰15å¤©ä¸æ‰“å¼€é“¾æ¥ï¼Œé‚£ä¹ˆä»–å°±æ²¡æ³•æ›´æ–°ï¼Œå¦‚æœæ¯”å¦‚è¯´ä¸€ä¸ªæœˆæ²¡æ‰“å¼€ï¼Œé‚£ä¹ˆå°±éœ€è¦æ”¹æˆ31ã€‚ä½†æ˜¯fixtureçš„æ•°æ®ä¸éœ€è¦æ¯å¤©è¿ç»­æ›´æ–°ï¼Œæ‰€ä»¥å¾€å‰æ¨ä¸¤å¤©å°±å¤Ÿäº†
    params={'from':datefrom,'to':dateto}
    url_tc='https://api.balticexchange.com/api/v1.3/feed/FDS08EK9KYT1G4A5POP8AX5PHUZWZYPZ/fixtureType/FXT3NN4TMQPQL3YB0HRAMQKPSI3CCLKO/data'
   # é€šè¿‡æ¥å£è·å–TC-FIXTURESæ•°æ®
    """
    "name": "TIMECHARTER",
     "apiIdentifier": "FXT3NN4TMQPQL3YB0HRAMQKPSI3CCLKO",
     "fixturesFrom": "2026-01-08",
     "fixturesTo": "2026-01-08",
     "fixtures": [
    {
      "date": "2026-01-08",
      "fixtureType": "TIMECHARTER",

    
    """
    #æ£€æŸ¥ä¸€ä¸‹è·å–åˆ°çš„æ•°æ®æ˜¯å¦æœ‰æ•ˆ
    try:
        response = requests.get(url_tc, headers=headers, params=params)
        response.raise_for_status()
        data = response.json()
        
        # æ£€æŸ¥è¿”å›æ•°æ®æ˜¯å¦æœ‰æ•ˆ
        if 'fixtures' not in data or not data['fixtures']:
            st.warning(f"No fixtures data returned for the period {datefrom.date()} to {dateto.date()}")
            return None
            
        df = pd.DataFrame(data)
        
    except requests.exceptions.RequestException as e:
        st.error(f"Error fetching data from TIMECHARTER API: {e}")
        return None
    use_cols = [
    'date', 'fixtureType', 'shipName', 
    'buildYear', 'dwt', 'deliveryPort', 'freeText', 'loadArea', 
    'charterer', 'comment', 'tripDescriptionPeriodInfo', 'viaPortReletRateBallastBonus','fixtureString']
       # ç¡®ä¿æ‰€æœ‰éœ€è¦çš„åˆ—éƒ½å­˜åœ¨
    # ç¡®ä¿æ‰€æœ‰éœ€è¦çš„åˆ—éƒ½å­˜åœ¨
    if 'fixtures' in df.columns and len(df) > 0:
        # ä¿®å¤ï¼šå¤„ç†fixtureså¯èƒ½ä¸ºå•ä¸ªå­—å…¸çš„æƒ…å†µ
        fixtures = df.loc[0, 'fixtures']
        
        # å¦‚æœfixturesæ˜¯å­—å…¸ï¼ˆå•ä¸ªæ•°æ®ç‚¹ï¼‰ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
        if isinstance(fixtures, dict):
            fixtures = [fixtures]
        
        # å¦‚æœfixturesæ˜¯ç©ºåˆ—è¡¨ï¼Œç›´æ¥è¿”å›None
        if not fixtures:
            st.warning("No fixtures data available in the response")
            return None
            
        fixtures_df = pd.DataFrame(fixtures)  # ç°åœ¨è¿™é‡Œåº”è¯¥æ˜¯å®‰å…¨çš„
        
        # å¦‚æœfixtures_dfä¸ºç©ºï¼Œç›´æ¥è¿”å›None
        if fixtures_df.empty:
            return None
        
        spot_tcfix = (fixtures_df[use_cols]
                      .pipe(enrich, maps=TC_RE_MAPS)
                      .assign(date=lambda x: pd.to_datetime(x['date'])))
        spot_tcfix.set_index('date', inplace=True)

        # æ·»åŠ  VESSEL TYPE åˆ—
        spot_tcfix = add_vessel_type(spot_tcfix)
        
        # è¯»å–æˆ–åˆ›å»ºæ—§æ•°æ®æ–‡ä»¶ï¼Œå¦‚æœæ²¡æœ‰æ—§æ•°æ®æ–‡ä»¶åˆ™åˆ›å»º
        file_path = 'timecharter.csv'
        if os.path.exists(file_path):
            spot_old = pd.read_csv(file_path, parse_dates=['date'])
            spot_old.set_index('date', inplace=True)

            # ç¡®ä¿æ—§æ•°æ®ä¹Ÿæœ‰ VESSEL TYPE åˆ—ï¼ˆå¦‚æœæ˜¯ä»æ—§ç‰ˆæœ¬å‡çº§ï¼‰
            if 'VESSEL TYPE' not in spot_old.columns:
                spot_old = add_vessel_type(spot_old)

            st.text(f'TIMECHARTER Fixtures Data Before Update: {spot_old.index[-1].date()}')
            
            # åˆå¹¶æ•°æ® - åªä¿ç•™ä¸åœ¨æ—§æ•°æ®ä¸­çš„æ–°æ•°æ®
            # å‡è®¾æ–°æ•°æ®çš„æ—¥æœŸéƒ½åœ¨æ—§æ•°æ®æœ€æ–°æ—¥æœŸä¹‹å
            last_date = spot_old.index.max()
            new_data = spot_tcfix[spot_tcfix.index > last_date]
            
            if not new_data.empty:
                spot = pd.concat([spot_old, new_data])
            else:
                spot = spot_old
                st.info("No new data to add.")
        else:
            spot = spot_tcfix
            st.text("Creating new data file.")
        
        # å»é‡
        spot = spot.reset_index()
        spot = spot.drop_duplicates(subset=['date', 'shipName'], keep='last')
        spot.set_index('date', inplace=True)
        spot.sort_index(inplace=True)
        
        st.text(f'TIMECHARTER Fixtures Data After Update: {spot.index[-1].date()}')
        st.text(f'Total records: {len(spot)}')
        
        # ä¿å­˜
        spot.to_csv(file_path, index_label='date')
        
        return spot
    
    else:
        st.warning("No tc fixtures data available.")
        return None

PERIOD_RE_MAPS={
    # chrträ¸åŒ¹é…äº†ï¼Œå› ä¸ºå¥½åƒéƒ½å†™äº†ï¼Œè€Œä¸”æ¯”è¾ƒéš¾åŒ¹é…ï¼Œå› ä¸ºä¸å¥½å®šä½--
    'shipName': re.compile(r"'([^']+)'", re.I), #æ‰¾åˆ°ç¬¬ä¸€å¯¹å•å¼•å·ï¼ŒæŠŠä¸­é—´ä¸æ˜¯å•å¼•å·çš„é‚£ä¸²å­—ç¬¦æŠ“å‡ºæ¥ï¼Œå°±æ˜¯èˆ¹åã€‚re.Iå¿½ç•¥å¤§å°å†™
    'buildYear': re.compile(r"'[^']+'\s+(\d{4})", re.I), #èˆ¹ååé¢çš„å››ä½æ•°å­—æŠ“å‡ºæ¥
    'dwt': re.compile(r"(\d+)\s+dwt", re.I), #dwtå‰ä¸€ä¸²æ•°å­—æŠ“å‡ºæ¥ï¼Œå³dwtçš„éƒ¨åˆ†
    'deliveryPort': re.compile(r"dely\s+(.*?)(?=\s+(?:\d+(?:/\d+)?\s+\w+|prompt)\s+)", re.I),#ä» dely åé¢å¼€å§‹ï¼Œä»»æ„å­—ç¬¦ï¼ˆéè´ªå©ªï¼‰ä¸€ç›´å¾€å‰æ‰«ï¼Œç›´åˆ°ç¬¬ä¸€æ¬¡å‡ºç°"æ•°å­—+ä»»æ„å•è¯ æˆ– "prompt" å°±åœï¼ŒæŠŠä¸­é—´é‚£æ®µä»»æ„å­—ç¬¦ä½œä¸ºäº¤èˆ¹æ¸¯å£åè¿”å›ã€‚
    'freeText': re.compile(r'dely[\s\S]*?\b(\d+(?:/\d+)?\s+[A-Za-z]+|prompt)(?=\s+redel\b)', re.I),#æŠ“ æ•°å­—+ä»»æ„é•¿åº¦æœˆä»½å•è¯ æˆ– prompt
    'comment': re.compile(r"<([^>]+)>", re.I),#å–ç¬¬ä¸€å¯¹å°–æ‹¬å· <...> ä¹‹é—´çš„ä»»æ„å­—ç¬¦
    'redel': re.compile(r'\bredel\s+(.*?)(?=\s*\$)', re.I),#redelå’Œ$ä¹‹é—´çš„å†…å®¹
    'hire': re.compile(r'(\$.*?)(?:\s*-|$)', re.I),#ä»ç¬¬ä¸€ä¸ªç¾å…ƒç¬¦å·å¼€å§‹ï¼Œä¸€ç›´ååˆ°ç¬¬ä¸€ä¸ª - æˆ–è¡Œå°¾ä¹‹å‰ç»“æŸï¼Œå†…å®¹ä¸é™
}
@st.cache_data()
def load_period_data(days_back: int = 1):
    headers = {'x-apikey': 'FMNNXJKJMSV6PE4YA36EOAAJXX1WAH84KSWNU8PEUFGRHUPJZA3QTG1FLE09SXJF'}
    dateto=pd.to_datetime('today')-BDay(1) #è·å–ä»£ç è¿è¡Œå½“æ—¥æ—¥æœŸ
    datefrom=dateto-BDay(days_back) #å‘å‰æ¨15ä¸ªå·¥ä½œæ—¥ï¼Œä¸è€ƒè™‘èŠ‚å‡æ—¥ï¼Œå¾—åˆ°15æ—¥çš„æ•°æ®ã€‚æ„æ€æ˜¯å…è®¸æ–­æ›´15å¤©ã€‚å› ä¸ºå¯èƒ½æœ‰15å¤©ä¸æ‰“å¼€é“¾æ¥ï¼Œé‚£ä¹ˆä»–å°±æ²¡æ³•æ›´æ–°ï¼Œå¦‚æœæ¯”å¦‚è¯´ä¸€ä¸ªæœˆæ²¡æ‰“å¼€ï¼Œé‚£ä¹ˆå°±éœ€è¦æ”¹æˆ31ã€‚ä½†æ˜¯fixtureçš„æ•°æ®ä¸éœ€è¦æ¯å¤©è¿ç»­æ›´æ–°ï¼Œæ‰€ä»¥å¾€å‰æ¨ä¸¤å¤©å°±å¤Ÿäº†
    params={'from':datefrom,'to':dateto}
    url_period='https://api.balticexchange.com/api/v1.3/feed/FDS08EK9KYT1G4A5POP8AX5PHUZWZYPZ/fixtureType/FXTTRVOV52RXY20H2JXIGEQ3JSK2LRDH/data'
    #æ£€æŸ¥ä¸€ä¸‹è·å–åˆ°çš„æ•°æ®æ˜¯å¦æœ‰æ•ˆ
    try:
        response = requests.get(url_period, headers=headers, params=params)
        response.raise_for_status()
        data = response.json()
        
        # æ£€æŸ¥è¿”å›æ•°æ®æ˜¯å¦æœ‰æ•ˆ
        if 'fixtures' not in data or not data['fixtures']:
            st.warning(f"No fixtures data returned for the period {datefrom.date()} to {dateto.date()}")
            return None
            
        df = pd.DataFrame(data)
        
    except requests.exceptions.RequestException as e:
        st.error(f"Error fetching data from Period API: {e}")
        return None
    use_cols = [
    'date', 'fixtureType', 'voyageType', 'shipName', 
    'buildYear', 'dwt', 'deliveryPort', 'freeText', 'loadArea', 
    'charterer', 'comment', 'tripDescriptionPeriodInfo', 'fixtureString']
    # ç¡®ä¿æ‰€æœ‰éœ€è¦çš„åˆ—éƒ½å­˜åœ¨
    if 'fixtures' in df.columns and len(df) > 0:
        # ä¿®å¤ï¼šå¤„ç†fixtureså¯èƒ½ä¸ºå•ä¸ªå­—å…¸çš„æƒ…å†µ
        fixtures = df.loc[0, 'fixtures']
        
        # å¦‚æœfixturesæ˜¯å­—å…¸ï¼ˆå•ä¸ªæ•°æ®ç‚¹ï¼‰ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
        if isinstance(fixtures, dict):
            fixtures = [fixtures]
        
        # å¦‚æœfixturesæ˜¯ç©ºåˆ—è¡¨ï¼Œç›´æ¥è¿”å›None
        if not fixtures:
            st.warning("No fixtures data available in the response")
            return None
            
        fixtures_df = pd.DataFrame(fixtures)  # ç°åœ¨è¿™é‡Œåº”è¯¥æ˜¯å®‰å…¨çš„
        
        # å¦‚æœfixtures_dfä¸ºç©ºï¼Œç›´æ¥è¿”å›None
        if fixtures_df.empty:
            return None
        
        spot_periodfix = (fixtures_df[use_cols]
                      .pipe(enrich, maps=PERIOD_RE_MAPS)
                      .assign(date=lambda x: pd.to_datetime(x['date'])))
        spot_periodfix.set_index('date', inplace=True)
        # æ·»åŠ  VESSEL TYPE åˆ—
        spot_periodfix = add_vessel_type(spot_periodfix)
        
        # è¯»å–æˆ–åˆ›å»ºæ—§æ•°æ®æ–‡ä»¶ï¼Œå¦‚æœæ²¡æœ‰æ—§æ•°æ®æ–‡ä»¶åˆ™åˆ›å»º
        file_path = 'periodcharter.csv'
        if os.path.exists(file_path):
            spot_old = pd.read_csv(file_path, parse_dates=['date'])
            spot_old.set_index('date', inplace=True)
            # ç¡®ä¿æ—§æ•°æ®ä¹Ÿæœ‰ VESSEL TYPE åˆ—ï¼ˆå¦‚æœæ˜¯ä»æ—§ç‰ˆæœ¬å‡çº§ï¼‰
            if 'VESSEL TYPE' not in spot_old.columns:
                spot_old = add_vessel_type(spot_old)
            st.text(f'PERIOD Fixtures Data Before Update: {spot_old.index[-1].date()}')
            
            # åˆå¹¶æ•°æ® - åªä¿ç•™ä¸åœ¨æ—§æ•°æ®ä¸­çš„æ–°æ•°æ®
            # å‡è®¾æ–°æ•°æ®çš„æ—¥æœŸéƒ½åœ¨æ—§æ•°æ®æœ€æ–°æ—¥æœŸä¹‹å
            last_date = spot_old.index.max()
            new_data = spot_periodfix[spot_periodfix.index > last_date]
            
            if not new_data.empty:
                spot = pd.concat([spot_old, new_data])
            else:
                spot = spot_old
                st.info("No new data to add.")
        else:
            spot = spot_periodfix
            st.text("Creating new data file.")
        
        # å»é‡
        spot = spot.reset_index()
        spot = spot.drop_duplicates(subset=['date', 'shipName'], keep='last')
        spot.set_index('date', inplace=True)
        spot.sort_index(inplace=True)
        
        st.text(f'PERIOD Fixtures Data After Update: {spot.index[-1].date()}')
        st.text(f'Total records: {len(spot)}')
        
        # ä¿å­˜
        spot.to_csv(file_path, index_label='date')
        
        return spot
    
    else:
        st.warning("No period fixtures data available.")
        return None

VC_RE_MAPS={
    # chrträ¸åŒ¹é…äº†ï¼Œå› ä¸ºå¥½åƒéƒ½å†™äº†ï¼Œè€Œä¸”æ¯”è¾ƒéš¾åŒ¹é…ï¼Œå› ä¸ºä¸å¥½å®šä½--
    'shipName': re.compile(r"'([^']+)'", re.I), #æ‰¾åˆ°ç¬¬ä¸€å¯¹å•å¼•å·ï¼ŒæŠŠä¸­é—´ä¸æ˜¯å•å¼•å·çš„é‚£ä¸²å­—ç¬¦æŠ“å‡ºæ¥ï¼Œå°±æ˜¯èˆ¹åã€‚re.Iå¿½ç•¥å¤§å°å†™
    'buildYear': re.compile(r"'[^']+'\s+(\d{4})", re.I), #èˆ¹ååé¢çš„å››ä½æ•°å­—æŠ“å‡ºæ¥
    'cargoSize': re.compile(r"(\d+/\d+)", re.I), #æŠŠ70000/5è¿™æ ·çš„æŠ“å‡ºæ¥
    'freeText': re.compile(r"\b(\d+(?:/\d+)?\s+[A-Za-z]+)\b", re.I),#æŠ“ æ•°å­—+ä»»æ„é•¿åº¦æœˆä»½å•è¯ æˆ– prompt
    'comment': re.compile(r"<([^>]+)>", re.I),#å–ç¬¬ä¸€å¯¹å°–æ‹¬å· <...> ä¹‹é—´çš„ä»»æ„å­—ç¬¦
    'freight': re.compile(r'(\$.*?)(?:\s*)', re.I),#ç¬¬ä¸€ä¸ªç¾å…ƒç¬¦å·å¼€å§‹ã€ç›´åˆ°é‡åˆ°ç©ºæ ¼å‰"çš„è¿è´¹é‡‘é¢
}
@st.cache_data()
def load_voyage_grain_data(days_back: int = 1):
    headers = {'x-apikey': 'FMNNXJKJMSV6PE4YA36EOAAJXX1WAH84KSWNU8PEUFGRHUPJZA3QTG1FLE09SXJF'}
    dateto=pd.to_datetime('today')-BDay(1) #è·å–ä»£ç è¿è¡Œå½“æ—¥æ—¥æœŸ
    datefrom=dateto-BDay(days_back) #å‘å‰æ¨15ä¸ªå·¥ä½œæ—¥ï¼Œä¸è€ƒè™‘èŠ‚å‡æ—¥ï¼Œå¾—åˆ°15æ—¥çš„æ•°æ®ã€‚æ„æ€æ˜¯å…è®¸æ–­æ›´15å¤©ã€‚å› ä¸ºå¯èƒ½æœ‰15å¤©ä¸æ‰“å¼€é“¾æ¥ï¼Œé‚£ä¹ˆä»–å°±æ²¡æ³•æ›´æ–°ï¼Œå¦‚æœæ¯”å¦‚è¯´ä¸€ä¸ªæœˆæ²¡æ‰“å¼€ï¼Œé‚£ä¹ˆå°±éœ€è¦æ”¹æˆ31ã€‚ä½†æ˜¯fixtureçš„æ•°æ®ä¸éœ€è¦æ¯å¤©è¿ç»­æ›´æ–°ï¼Œæ‰€ä»¥å¾€å‰æ¨ä¸¤å¤©å°±å¤Ÿäº†
    params={'from':datefrom,'to':dateto}
    url_voyage_grain='https://api.balticexchange.com/api/v1.3/feed/FDS08EK9KYT1G4A5POP8AX5PHUZWZYPZ/fixtureType/FXTK49ZE0UEYV553O9AMBJAC201AUIBG/data'
    #æ£€æŸ¥ä¸€ä¸‹è·å–åˆ°çš„æ•°æ®æ˜¯å¦æœ‰æ•ˆ
    try:
        response = requests.get(url_voyage_grain, headers=headers, params=params)
        response.raise_for_status()
        data = response.json()
        
        # æ£€æŸ¥è¿”å›æ•°æ®æ˜¯å¦æœ‰æ•ˆ
        if 'fixtures' not in data or not data['fixtures']:
            st.warning(f"No fixtures data returned for the period {datefrom.date()} to {dateto.date()}")
            return None
            
        df = pd.DataFrame(data)
        
    except requests.exceptions.RequestException as e:
        st.error(f"Error fetching data from voyage grain API: {e}")
        return None
    use_cols = [
    'date', 'fixtureType', 'cargoSize','voyageType', 'shipName', 
    'buildYear', 'dwt',  'freeText', 'loadPort', 'dischargePort','rateAndTerms',
    'charterer', 'comment','fixtureString']
    # ç¡®ä¿æ‰€æœ‰éœ€è¦çš„åˆ—éƒ½å­˜åœ¨
    if 'fixtures' in df.columns and len(df) > 0:
        # ä¿®å¤ï¼šå¤„ç†fixtureså¯èƒ½ä¸ºå•ä¸ªå­—å…¸çš„æƒ…å†µ
        fixtures = df.loc[0, 'fixtures']
        
        # å¦‚æœfixturesæ˜¯å­—å…¸ï¼ˆå•ä¸ªæ•°æ®ç‚¹ï¼‰ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
        if isinstance(fixtures, dict):
            fixtures = [fixtures]
        
        # å¦‚æœfixturesæ˜¯ç©ºåˆ—è¡¨ï¼Œç›´æ¥è¿”å›None
        if not fixtures:
            st.warning("No fixtures data available in the response")
            return None
            
        fixtures_df = pd.DataFrame(fixtures)  # ç°åœ¨è¿™é‡Œåº”è¯¥æ˜¯å®‰å…¨çš„
        
        # å¦‚æœfixtures_dfä¸ºç©ºï¼Œç›´æ¥è¿”å›None
        if fixtures_df.empty:
            return None
        
        spot_vcgrfix = (fixtures_df[use_cols]
                      .pipe(enrich, maps=VC_RE_MAPS)
                      .assign(date=lambda x: pd.to_datetime(x['date'])))
        spot_vcgrfix.set_index('date', inplace=True)
        # æ·»åŠ  VESSEL TYPE åˆ—
        spot_vcgrfix = add_vessel_type(spot_vcgrfix)
        
        # è¯»å–æˆ–åˆ›å»ºæ—§æ•°æ®æ–‡ä»¶ï¼Œå¦‚æœæ²¡æœ‰æ—§æ•°æ®æ–‡ä»¶åˆ™åˆ›å»º
        file_path = 'vcgrain.csv'
        if os.path.exists(file_path):
            spot_old = pd.read_csv(file_path, parse_dates=['date'])
            spot_old.set_index('date', inplace=True)
            # ç¡®ä¿æ—§æ•°æ®ä¹Ÿæœ‰ VESSEL TYPE åˆ—ï¼ˆå¦‚æœæ˜¯ä»æ—§ç‰ˆæœ¬å‡çº§ï¼‰
            if 'VESSEL TYPE' not in spot_old.columns:
                spot_old = add_vessel_type(spot_old)
            st.text(f'VOYAGE(GRAIN) Fixtures Data Before Update: {spot_old.index[-1].date()}')
            
            # åˆå¹¶æ•°æ® - åªä¿ç•™ä¸åœ¨æ—§æ•°æ®ä¸­çš„æ–°æ•°æ®
            # å‡è®¾æ–°æ•°æ®çš„æ—¥æœŸéƒ½åœ¨æ—§æ•°æ®æœ€æ–°æ—¥æœŸä¹‹å
            last_date = spot_old.index.max()
            new_data = spot_vcgrfix[spot_vcgrfix.index > last_date]
            
            if not new_data.empty:
                spot = pd.concat([spot_old, new_data])
            else:
                spot = spot_old
                st.info("No new data to add.")
        else:
            spot = spot_vcgrfix
            st.text("Creating new data file.")
        
        # å»é‡
        spot = spot.reset_index()
        spot = spot.drop_duplicates(subset=['date', 'shipName'], keep='last')
        spot.set_index('date', inplace=True)
        spot.sort_index(inplace=True)
        
        st.text(f'VOYAGE(GRAIN) Fixtures Data After Update: {spot.index[-1].date()}')
        st.text(f'Total records: {len(spot)}')
        
        # ä¿å­˜
        spot.to_csv(file_path, index_label='date')
        
        return spot
    
    else:
        st.warning("No voyage grain fixtures data available.")
        return None


@st.cache_data()
def load_voyage_coal_data(days_back: int = 1):
    headers = {'x-apikey': 'FMNNXJKJMSV6PE4YA36EOAAJXX1WAH84KSWNU8PEUFGRHUPJZA3QTG1FLE09SXJF'}
    dateto=pd.to_datetime('today')-BDay(1) #è·å–ä»£ç è¿è¡Œå½“æ—¥æ—¥æœŸ
    datefrom=dateto-BDay(days_back) #å‘å‰æ¨15ä¸ªå·¥ä½œæ—¥ï¼Œä¸è€ƒè™‘èŠ‚å‡æ—¥ï¼Œå¾—åˆ°15æ—¥çš„æ•°æ®ã€‚æ„æ€æ˜¯å…è®¸æ–­æ›´15å¤©ã€‚å› ä¸ºå¯èƒ½æœ‰15å¤©ä¸æ‰“å¼€é“¾æ¥ï¼Œé‚£ä¹ˆä»–å°±æ²¡æ³•æ›´æ–°ï¼Œå¦‚æœæ¯”å¦‚è¯´ä¸€ä¸ªæœˆæ²¡æ‰“å¼€ï¼Œé‚£ä¹ˆå°±éœ€è¦æ”¹æˆ31ã€‚ä½†æ˜¯fixtureçš„æ•°æ®ä¸éœ€è¦æ¯å¤©è¿ç»­æ›´æ–°ï¼Œæ‰€ä»¥å¾€å‰æ¨ä¸¤å¤©å°±å¤Ÿäº†
    params={'from':datefrom,'to':dateto}
    url_voyage_coal='https://api.balticexchange.com/api/v1.3/feed/FDS08EK9KYT1G4A5POP8AX5PHUZWZYPZ/fixtureType/FXTUG0D1YCOCHBLVRKBQPXIXI6L2X5TA/data'
    #æ£€æŸ¥ä¸€ä¸‹è·å–åˆ°çš„æ•°æ®æ˜¯å¦æœ‰æ•ˆ
    try:
        response = requests.get(url_voyage_coal, headers=headers, params=params)
        response.raise_for_status()
        data = response.json()
        
        # æ£€æŸ¥è¿”å›æ•°æ®æ˜¯å¦æœ‰æ•ˆ
        if 'fixtures' not in data or not data['fixtures']:
            st.warning(f"No fixtures data returned for the period {datefrom.date()} to {dateto.date()}")
            return None
            
        df = pd.DataFrame(data)
        
    except requests.exceptions.RequestException as e:
        st.error(f"Error fetching data from voyage coal API: {e}")
        return None
    use_cols = [
    'date', 'fixtureType', 'cargoSize','voyageType', 'shipName', 
    'buildYear', 'dwt',  'freeText', 'loadPort', 'dischargePort','rateAndTerms',
    'charterer', 'comment','fixtureString']
    # ç¡®ä¿æ‰€æœ‰éœ€è¦çš„åˆ—éƒ½å­˜åœ¨
    if 'fixtures' in df.columns and len(df) > 0:
        # ä¿®å¤ï¼šå¤„ç†fixtureså¯èƒ½ä¸ºå•ä¸ªå­—å…¸çš„æƒ…å†µ
        fixtures = df.loc[0, 'fixtures']
        
        # å¦‚æœfixturesæ˜¯å­—å…¸ï¼ˆå•ä¸ªæ•°æ®ç‚¹ï¼‰ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
        if isinstance(fixtures, dict):
            fixtures = [fixtures]
        
        # å¦‚æœfixturesæ˜¯ç©ºåˆ—è¡¨ï¼Œç›´æ¥è¿”å›None
        if not fixtures:
            st.warning("No fixtures data available in the response")
            return None
            
        fixtures_df = pd.DataFrame(fixtures)  # ç°åœ¨è¿™é‡Œåº”è¯¥æ˜¯å®‰å…¨çš„
        
        # å¦‚æœfixtures_dfä¸ºç©ºï¼Œç›´æ¥è¿”å›None
        if fixtures_df.empty:
            return None
        
        spot_vccofix = (fixtures_df[use_cols]
                      .pipe(enrich, maps=VC_RE_MAPS)
                      .assign(date=lambda x: pd.to_datetime(x['date'])))
        spot_vccofix.set_index('date', inplace=True)
        # æ·»åŠ  VESSEL TYPE åˆ—
        spot_vccofix = add_vessel_type(spot_vccofix)
        
        # è¯»å–æˆ–åˆ›å»ºæ—§æ•°æ®æ–‡ä»¶ï¼Œå¦‚æœæ²¡æœ‰æ—§æ•°æ®æ–‡ä»¶åˆ™åˆ›å»º
        file_path = 'vccoal.csv'
        if os.path.exists(file_path):
            spot_old = pd.read_csv(file_path, parse_dates=['date'])
            spot_old.set_index('date', inplace=True)
            # ç¡®ä¿æ—§æ•°æ®ä¹Ÿæœ‰ VESSEL TYPE åˆ—ï¼ˆå¦‚æœæ˜¯ä»æ—§ç‰ˆæœ¬å‡çº§ï¼‰
            if 'VESSEL TYPE' not in spot_old.columns:
                spot_old = add_vessel_type(spot_old)
            st.text(f'VOYAGE(COAL) Fixtures Data Before Update: {spot_old.index[-1].date()}')
            
            # åˆå¹¶æ•°æ® - åªä¿ç•™ä¸åœ¨æ—§æ•°æ®ä¸­çš„æ–°æ•°æ®
            # å‡è®¾æ–°æ•°æ®çš„æ—¥æœŸéƒ½åœ¨æ—§æ•°æ®æœ€æ–°æ—¥æœŸä¹‹å
            last_date = spot_old.index.max()
            new_data = spot_vccofix[spot_vccofix.index > last_date]
            
            if not new_data.empty:
                spot = pd.concat([spot_old, new_data])
            else:
                spot = spot_old
                st.info("No new data to add.")
        else:
            spot = spot_vccofix
            st.text("Creating new data file.")
        
        # å»é‡
        spot = spot.reset_index()
        spot = spot.drop_duplicates(subset=['date', 'shipName'], keep='last')
        spot.set_index('date', inplace=True)
        spot.sort_index(inplace=True)
        
        st.text(f'VOYAGE(COAL) Fixtures Data After Update: {spot.index[-1].date()}')
        st.text(f'Total records: {len(spot)}')
        
        # ä¿å­˜
        spot.to_csv(file_path, index_label='date')
        
        return spot
    
    else:
        st.warning("No voyage coal fixtures data available.")
        return None


@st.cache_data()
def load_voyage_misc_data(days_back: int = 1):
    headers = {'x-apikey': 'FMNNXJKJMSV6PE4YA36EOAAJXX1WAH84KSWNU8PEUFGRHUPJZA3QTG1FLE09SXJF'}
    dateto=pd.to_datetime('today')-BDay(1) #è·å–ä»£ç è¿è¡Œå½“æ—¥æ—¥æœŸ
    datefrom=dateto-BDay(days_back) #å‘å‰æ¨15ä¸ªå·¥ä½œæ—¥ï¼Œä¸è€ƒè™‘èŠ‚å‡æ—¥ï¼Œå¾—åˆ°15æ—¥çš„æ•°æ®ã€‚æ„æ€æ˜¯å…è®¸æ–­æ›´15å¤©ã€‚å› ä¸ºå¯èƒ½æœ‰15å¤©ä¸æ‰“å¼€é“¾æ¥ï¼Œé‚£ä¹ˆä»–å°±æ²¡æ³•æ›´æ–°ï¼Œå¦‚æœæ¯”å¦‚è¯´ä¸€ä¸ªæœˆæ²¡æ‰“å¼€ï¼Œé‚£ä¹ˆå°±éœ€è¦æ”¹æˆ31ã€‚ä½†æ˜¯fixtureçš„æ•°æ®ä¸éœ€è¦æ¯å¤©è¿ç»­æ›´æ–°ï¼Œæ‰€ä»¥å¾€å‰æ¨ä¸¤å¤©å°±å¤Ÿäº†
    params={'from':datefrom,'to':dateto}
    url_voyage_misc='https://api.balticexchange.com/api/v1.3/feed/FDS08EK9KYT1G4A5POP8AX5PHUZWZYPZ/fixtureType/FXTLE3TOJ4YRBE3VAD4TWRY42LOJUKET/data'
    #æ£€æŸ¥ä¸€ä¸‹è·å–åˆ°çš„æ•°æ®æ˜¯å¦æœ‰æ•ˆ
    try:
        response = requests.get(url_voyage_misc, headers=headers, params=params)
        response.raise_for_status()
        data = response.json()
        
        # æ£€æŸ¥è¿”å›æ•°æ®æ˜¯å¦æœ‰æ•ˆ
        if 'fixtures' not in data or not data['fixtures']:
            st.warning(f"No fixtures data returned for the period {datefrom.date()} to {dateto.date()}")
            return None
            
        df = pd.DataFrame(data)
        
    except requests.exceptions.RequestException as e:
        st.error(f"Error fetching data from voyage misc API: {e}")
        return None
    use_cols = [
    'date', 'fixtureType', 'cargoSize','voyageType', 'shipName', 
    'buildYear', 'dwt',  'freeText', 'loadPort', 'dischargePort','rateAndTerms',
    'charterer', 'comment','fixtureString']
    # ç¡®ä¿æ‰€æœ‰éœ€è¦çš„åˆ—éƒ½å­˜åœ¨
    if 'fixtures' in df.columns and len(df) > 0:
        # ä¿®å¤ï¼šå¤„ç†fixtureså¯èƒ½ä¸ºå•ä¸ªå­—å…¸çš„æƒ…å†µ
        fixtures = df.loc[0, 'fixtures']
        
        # å¦‚æœfixturesæ˜¯å­—å…¸ï¼ˆå•ä¸ªæ•°æ®ç‚¹ï¼‰ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
        if isinstance(fixtures, dict):
            fixtures = [fixtures]
        
        # å¦‚æœfixturesæ˜¯ç©ºåˆ—è¡¨ï¼Œç›´æ¥è¿”å›None
        if not fixtures:
            st.warning("No fixtures data available in the response")
            return None
            
        fixtures_df = pd.DataFrame(fixtures)  # ç°åœ¨è¿™é‡Œåº”è¯¥æ˜¯å®‰å…¨çš„
        
        # å¦‚æœfixtures_dfä¸ºç©ºï¼Œç›´æ¥è¿”å›None
        if fixtures_df.empty:
            return None
        
        spot_vcmifix = (fixtures_df[use_cols]
                      .pipe(enrich, maps=VC_RE_MAPS)
                      .assign(date=lambda x: pd.to_datetime(x['date'])))
        spot_vcmifix.set_index('date', inplace=True)
         # æ·»åŠ  VESSEL TYPE åˆ—
        spot_vcmifix = add_vessel_type(spot_vcmifix)       
        # è¯»å–æˆ–åˆ›å»ºæ—§æ•°æ®æ–‡ä»¶ï¼Œå¦‚æœæ²¡æœ‰æ—§æ•°æ®æ–‡ä»¶åˆ™åˆ›å»º
        file_path = 'vcmisc.csv'
        if os.path.exists(file_path):
            spot_old = pd.read_csv(file_path, parse_dates=['date'])
            spot_old.set_index('date', inplace=True)
            # ç¡®ä¿æ—§æ•°æ®ä¹Ÿæœ‰ VESSEL TYPE åˆ—ï¼ˆå¦‚æœæ˜¯ä»æ—§ç‰ˆæœ¬å‡çº§ï¼‰
            if 'VESSEL TYPE' not in spot_old.columns:
                spot_old = add_vessel_type(spot_old)
            st.text(f'VOYAGE(MISC) Fixtures Data Before Update: {spot_old.index[-1].date()}')
            
            # åˆå¹¶æ•°æ® - åªä¿ç•™ä¸åœ¨æ—§æ•°æ®ä¸­çš„æ–°æ•°æ®
            # å‡è®¾æ–°æ•°æ®çš„æ—¥æœŸéƒ½åœ¨æ—§æ•°æ®æœ€æ–°æ—¥æœŸä¹‹å
            last_date = spot_old.index.max()
            new_data = spot_vcmifix[spot_vcmifix.index > last_date]
            
            if not new_data.empty:
                spot = pd.concat([spot_old, new_data])
            else:
                spot = spot_old
                st.info("No new data to add.")
        else:
            spot = spot_vcmifix
            st.text("Creating new data file.")
        
        # å»é‡
        spot = spot.reset_index()
        spot = spot.drop_duplicates(subset=['date', 'shipName'], keep='last')
        spot.set_index('date', inplace=True)
        spot.sort_index(inplace=True)
        
        st.text(f'VOYAGE(MISC) Fixtures Data After Update: {spot.index[-1].date()}')
        st.text(f'Total records: {len(spot)}')
        
        # ä¿å­˜
        spot.to_csv(file_path, index_label='date')
        
        return spot
    
    else:
        st.warning("No voyage misc fixtures data available.")
        return None
    

@st.cache_data()
def load_voyage_ore_data(days_back: int = 1):
    headers = {'x-apikey': 'FMNNXJKJMSV6PE4YA36EOAAJXX1WAH84KSWNU8PEUFGRHUPJZA3QTG1FLE09SXJF'}
    dateto=pd.to_datetime('today')-BDay(1) #è·å–ä»£ç è¿è¡Œå½“æ—¥æ—¥æœŸ
    datefrom=dateto-BDay(days_back) #å‘å‰æ¨15ä¸ªå·¥ä½œæ—¥ï¼Œä¸è€ƒè™‘èŠ‚å‡æ—¥ï¼Œå¾—åˆ°15æ—¥çš„æ•°æ®ã€‚æ„æ€æ˜¯å…è®¸æ–­æ›´15å¤©ã€‚å› ä¸ºå¯èƒ½æœ‰15å¤©ä¸æ‰“å¼€é“¾æ¥ï¼Œé‚£ä¹ˆä»–å°±æ²¡æ³•æ›´æ–°ï¼Œå¦‚æœæ¯”å¦‚è¯´ä¸€ä¸ªæœˆæ²¡æ‰“å¼€ï¼Œé‚£ä¹ˆå°±éœ€è¦æ”¹æˆ31ã€‚ä½†æ˜¯fixtureçš„æ•°æ®ä¸éœ€è¦æ¯å¤©è¿ç»­æ›´æ–°ï¼Œæ‰€ä»¥å¾€å‰æ¨ä¸¤å¤©å°±å¤Ÿäº†
    params={'from':datefrom,'to':dateto}
    url_voyage_ore='https://api.balticexchange.com/api/v1.3/feed/FDS08EK9KYT1G4A5POP8AX5PHUZWZYPZ/fixtureType/FXT1RAFAFHAFWQM3SKLQ4SE9TQ4VTT2O/data'
   # é€šè¿‡æ¥å£è·å–TC-FIXTURESæ•°æ®
    #æ£€æŸ¥ä¸€ä¸‹è·å–åˆ°çš„æ•°æ®æ˜¯å¦æœ‰æ•ˆ
    try:
        response = requests.get(url_voyage_ore, headers=headers, params=params)
        response.raise_for_status()
        data = response.json()
        
        # æ£€æŸ¥è¿”å›æ•°æ®æ˜¯å¦æœ‰æ•ˆ
        if 'fixtures' not in data or not data['fixtures']:
            st.warning(f"No fixtures data returned for the period {datefrom.date()} to {dateto.date()}")
            return None
            
        df = pd.DataFrame(data)
        
    except requests.exceptions.RequestException as e:
        st.error(f"Error fetching data from voyage ore API: {e}")
        return None
    use_cols = [
    'date', 'fixtureType', 'cargoSize','voyageType', 'shipName', 
    'buildYear', 'dwt',  'freeText', 'loadPort', 'dischargePort','rateAndTerms',
    'charterer', 'comment','fixtureString']
    # ç¡®ä¿æ‰€æœ‰éœ€è¦çš„åˆ—éƒ½å­˜åœ¨
    if 'fixtures' in df.columns and len(df) > 0:
        # ä¿®å¤ï¼šå¤„ç†fixtureså¯èƒ½ä¸ºå•ä¸ªå­—å…¸çš„æƒ…å†µ
        fixtures = df.loc[0, 'fixtures']
        
        # å¦‚æœfixturesæ˜¯å­—å…¸ï¼ˆå•ä¸ªæ•°æ®ç‚¹ï¼‰ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
        if isinstance(fixtures, dict):
            fixtures = [fixtures]
        
        # å¦‚æœfixturesæ˜¯ç©ºåˆ—è¡¨ï¼Œç›´æ¥è¿”å›None
        if not fixtures:
            st.warning("No fixtures data available in the response")
            return None
            
        fixtures_df = pd.DataFrame(fixtures)  # ç°åœ¨è¿™é‡Œåº”è¯¥æ˜¯å®‰å…¨çš„
        
        # å¦‚æœfixtures_dfä¸ºç©ºï¼Œç›´æ¥è¿”å›None
        if fixtures_df.empty:
            return None
        
        spot_vcorfix = (fixtures_df[use_cols]
                      .pipe(enrich, maps=VC_RE_MAPS)
                      .assign(date=lambda x: pd.to_datetime(x['date'])))
        spot_vcorfix.set_index('date', inplace=True)
         # æ·»åŠ  VESSEL TYPE åˆ—
        spot_vcorfix = add_vessel_type(spot_vcorfix)       
        # è¯»å–æˆ–åˆ›å»ºæ—§æ•°æ®æ–‡ä»¶ï¼Œå¦‚æœæ²¡æœ‰æ—§æ•°æ®æ–‡ä»¶åˆ™åˆ›å»º
        file_path = 'vcore.csv'
        if os.path.exists(file_path):
            spot_old = pd.read_csv(file_path, parse_dates=['date'])
            spot_old.set_index('date', inplace=True)
            # ç¡®ä¿æ—§æ•°æ®ä¹Ÿæœ‰ VESSEL TYPE åˆ—ï¼ˆå¦‚æœæ˜¯ä»æ—§ç‰ˆæœ¬å‡çº§ï¼‰
            if 'VESSEL TYPE' not in spot_old.columns:
                spot_old = add_vessel_type(spot_old)
            st.text(f'VOYAGE(ORE) Fixtures Data Before Update: {spot_old.index[-1].date()}')
            
            # åˆå¹¶æ•°æ® - åªä¿ç•™ä¸åœ¨æ—§æ•°æ®ä¸­çš„æ–°æ•°æ®
            # å‡è®¾æ–°æ•°æ®çš„æ—¥æœŸéƒ½åœ¨æ—§æ•°æ®æœ€æ–°æ—¥æœŸä¹‹å
            last_date = spot_old.index.max()
            new_data = spot_vcorfix[spot_vcorfix.index > last_date]
            
            if not new_data.empty:
                spot = pd.concat([spot_old, new_data])
            else:
                spot = spot_old
                st.info("No new data to add.")
        else:
            spot = spot_vcorfix
            st.text("Creating new data file.")
        
        # å»é‡
        spot = spot.reset_index()
        spot = spot.drop_duplicates(subset=['date', 'shipName'], keep='last')
        spot.set_index('date', inplace=True)
        spot.sort_index(inplace=True)
        
        st.text(f'VOYAGE(ORE) Fixtures Data After Update: {spot.index[-1].date()}')
        st.text(f'Total records: {len(spot)}')
        
        # ä¿å­˜
        spot.to_csv(file_path, index_label='date')
        
        return spot
    
    else:
        st.warning("No voyage misc fixtures data available.")
        return None




#æ‰‹åŠ¨æ‹‰å–å‰15å¤©çš„æ•°æ®ï¼Œé¿å…æ–­æ›´äº§ç”Ÿçš„å½±å“
def update_data():
    # 1) æ¸…æ‰æ‰€æœ‰æ—§ç¼“å­˜
    st.cache_data.clear()
    # 2) å‘Šè¯‰ loader è¿™æ¬¡è¦æŠ“ 15 å¤©
    st.session_state['force_15_days'] = True #å¦‚æœç”¨æˆ·ç‚¹è¿‡æ›´æ–°å‡½æ•°ï¼Œé‚£ä¹ˆsessioné‡Œä¼šå­˜åœ¨force_15_daysçš„key
    # å¾—åˆ°trueä¹‹åéœ€è¦é‡æ–°è¿è¡Œè„šæœ¬ï¼Œæ‰èƒ½ä½¿ç”¨
    st.rerun() #æ‹¿åˆ°trueä¹‹åç«‹å³é‡æ–°è¿è¡Œè„šæœ¬

#å¦‚æœsessioné‡Œä¼šå­˜åœ¨force_15_daysçš„keyï¼Œé‚£ä¹ˆdays_backå°±è®¾ç½®ä¸º15ï¼Œç”¨popæ˜¯ç”¨ä¸€æ¬¡ä¹‹åå°±åˆ æ‰
days_back = 3 if st.session_state.pop('force_15_days', None) else 1 

"""
pop(key, None) ä¼šæŠŠ key å¯¹åº”çš„å€¼å–å‡ºæ¥åŒæ—¶åˆ æ‰ï¼›å¦‚æœ key ä¸å­˜åœ¨å°±è¿”å› Noneã€‚
å› æ­¤ï¼š
â€“ ç”¨æˆ·æ²¡ç‚¹æŒ‰é’® â†’ æ²¡æœ‰ 'force_15_days' â†’ pop è¿”å› None â†’ days_back = 2ï¼ˆæ—¥å¸¸å¢é‡ï¼‰ã€‚
â€“ ç”¨æˆ·ç‚¹äº†æŒ‰é’® â†’ å›è°ƒé‡ŒæŠŠ 'force_15_days' è®¾æˆ True â†’ è„šæœ¬ç«‹å³ st.rerun() â†’ ç¬¬äºŒæ¬¡è·‘åˆ°è¿™é‡Œæ—¶ pop å–å‡º True å¹¶åˆ æ‰ â†’ days_back = 15ï¼ˆè¡¥ 15 å¤©ï¼‰ã€‚
â€“ å†ä¸‹ä¸€æ¬¡åˆ·æ–°é¡µé¢ â†’ æ ‡è®°å·²è¢«åˆ  â†’ åˆå›åˆ° 2ã€‚

"""
 
time.sleep(1)  # åˆå§‹å»¶è¿Ÿ
tc_spot = load_tc_data(days_back)
if 'tc_spot' not in st.session_state:
    st.session_state['tc_spot'] = tc_spot

time.sleep(1)  # è¯·æ±‚ä¹‹é—´æ·»åŠ å»¶è¿Ÿ
period_spot = load_period_data(days_back)
if 'period_spot' not in st.session_state:
    st.session_state['period_spot'] = period_spot

time.sleep(1)
vcgr_spot = load_voyage_grain_data(days_back)
if 'vcgr_spot' not in st.session_state:
    st.session_state['vcgr_spot'] = vcgr_spot

time.sleep(1)
vcco_spot = load_voyage_coal_data(days_back)
if 'vcco_spot' not in st.session_state:
    st.session_state['vcco_spot'] = vcco_spot

time.sleep(1)
vcmi_spot = load_voyage_misc_data(days_back)
if 'vcmi_spot' not in st.session_state:
    st.session_state['vcmi_spot'] = vcmi_spot

time.sleep(1)
vcor_spot = load_voyage_ore_data(days_back)
if 'vcor_spot' not in st.session_state:
    st.session_state['vcor_spot'] = vcor_spot

st.text('Fixture Data Done')
st.write('All Data Loaded!!')

st.button('Update Data',on_click=update_data) #æŒ‰é’®é“¾æ¥æ›´æ–°å‡½æ•°
st.text('Data will be updated when streamlit is opened')
st.text('If you would like to trigger the reload right now, please click on the above "Update Data" button.') 
